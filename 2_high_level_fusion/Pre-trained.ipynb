{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enter path to the data_fusion_guest_lecture file\n",
    "image_folder_path = \"data\"  \n",
    "\n",
    "# Loads labels\n",
    "df = pd.read_csv(os.path.join(image_folder_path, \"seedling_labels.csv\"))\n",
    "\n",
    "# Creates path to top & side view\n",
    "df[\"color_cam_path\"] = image_folder_path + \"/\" + df[\"color_cam_path\"]\n",
    "df[\"side_cam_path\"] = image_folder_path + \"/\" + df[\"side_cam_path\"]\n",
    "\n",
    "# Gives average expert label as a starting point\n",
    "df[\"average_expert\"] = (df[\"Expert 1\"] + df[\"Expert 2\"]  + df[\"Expert 3\"] + df[\"Expert 4\"]) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a score using Cohen Kappa for each expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "def compute_label_01(x, experts_weights):\n",
    "    labels = np.array([x['Expert 1'], x['Expert 2'], x['Expert 3'], x['Expert 4']]) # possible values [1, 2, 3, 4]\n",
    "    labels_normalized = ((labels - 1) * 2) - 3 # possible values [-3, -1, +1, +3]\n",
    "\n",
    "    label = (np.sum(labels_normalized * experts_weights)+3) / 6\n",
    "    return round(label + 1e-10, 9)\n",
    "def get_experts_weights(df):\n",
    "\texperts = [\"Expert 1\", \"Expert 2\", \"Expert 3\", \"Expert 4\"]\n",
    "\texperts_kappas = [[], [], [], []]\n",
    "\n",
    "\tfor pair in combinations(range(len(experts)), 2):\n",
    "\t\tlabels_expert_0 = df[experts[pair[0]]].values.tolist()\n",
    "\t\tlabels_expert_1 = df[experts[pair[1]]].values.tolist()\n",
    "\t\tkappa = cohen_kappa_score(labels_expert_0, labels_expert_1)\n",
    "\n",
    "\t\texperts_kappas[pair[0]].append(kappa)\n",
    "\t\texperts_kappas[pair[1]].append(kappa)\n",
    "\n",
    "\texperts_kappas = np.array(experts_kappas).mean(axis=1)\n",
    "\texperts_weights = experts_kappas / np.sum(experts_kappas)\n",
    "\n",
    "\treturn experts_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts_weights = get_experts_weights(df)\n",
    "df['Label'] = df.apply(lambda x: compute_label_01(x, experts_weights), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert (1,2 = normal, 3,4 = abnormal) because it will be binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expert 1</th>\n",
       "      <th>Expert 2</th>\n",
       "      <th>Expert 3</th>\n",
       "      <th>Expert 4</th>\n",
       "      <th>color_cam_path</th>\n",
       "      <th>side_cam_path</th>\n",
       "      <th>Rfid</th>\n",
       "      <th>Pos</th>\n",
       "      <th>average_expert</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data/A1/00387 Plant 0000 Plant 0000/18-02-2019...</td>\n",
       "      <td>data/A1/00387 Plant 0000 Plant 0000/18-02-2019...</td>\n",
       "      <td>A1</td>\n",
       "      <td>Plant 0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/A1/00388 Plant 0001 Plant 0001/18-02-2019...</td>\n",
       "      <td>data/A1/00388 Plant 0001 Plant 0001/18-02-2019...</td>\n",
       "      <td>A1</td>\n",
       "      <td>Plant 0001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/A1/00389 Plant 0002 Plant 0002/18-02-2019...</td>\n",
       "      <td>data/A1/00389 Plant 0002 Plant 0002/18-02-2019...</td>\n",
       "      <td>A1</td>\n",
       "      <td>Plant 0002</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data/A1/00390 Plant 0003 Plant 0003/18-02-2019...</td>\n",
       "      <td>data/A1/00390 Plant 0003 Plant 0003/18-02-2019...</td>\n",
       "      <td>A1</td>\n",
       "      <td>Plant 0003</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/A1/00391 Plant 0004 Plant 0004/18-02-2019...</td>\n",
       "      <td>data/A1/00391 Plant 0004 Plant 0004/18-02-2019...</td>\n",
       "      <td>A1</td>\n",
       "      <td>Plant 0004</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/B4/01019 Plant 0122 Plant 0122/18-02-2019...</td>\n",
       "      <td>data/B4/01019 Plant 0122 Plant 0122/18-02-2019...</td>\n",
       "      <td>B4</td>\n",
       "      <td>Plant 0122</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/B4/01020 Plant 0123 Plant 0123/18-02-2019...</td>\n",
       "      <td>data/B4/01020 Plant 0123 Plant 0123/18-02-2019...</td>\n",
       "      <td>B4</td>\n",
       "      <td>Plant 0123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/B4/01021 Plant 0124 Plant 0124/18-02-2019...</td>\n",
       "      <td>data/B4/01021 Plant 0124 Plant 0124/18-02-2019...</td>\n",
       "      <td>B4</td>\n",
       "      <td>Plant 0124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data/B4/01022 Plant 0125 Plant 0125/18-02-2019...</td>\n",
       "      <td>data/B4/01022 Plant 0125 Plant 0125/18-02-2019...</td>\n",
       "      <td>B4</td>\n",
       "      <td>Plant 0125</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data/B4/01023 Plant 0126 Plant 0126/18-02-2019...</td>\n",
       "      <td>data/B4/01023 Plant 0126 Plant 0126/18-02-2019...</td>\n",
       "      <td>B4</td>\n",
       "      <td>Plant 0126</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Expert 1  Expert 2  Expert 3  Expert 4  \\\n",
       "0           1         1         1         1   \n",
       "1           0         0         0         0   \n",
       "2           0         0         0         0   \n",
       "3           1         1         1         1   \n",
       "4           1         0         0         0   \n",
       "..        ...       ...       ...       ...   \n",
       "989         0         0         0         0   \n",
       "990         0         0         0         0   \n",
       "991         0         0         0         0   \n",
       "992         0         1         1         1   \n",
       "993         1         1         1         1   \n",
       "\n",
       "                                        color_cam_path  \\\n",
       "0    data/A1/00387 Plant 0000 Plant 0000/18-02-2019...   \n",
       "1    data/A1/00388 Plant 0001 Plant 0001/18-02-2019...   \n",
       "2    data/A1/00389 Plant 0002 Plant 0002/18-02-2019...   \n",
       "3    data/A1/00390 Plant 0003 Plant 0003/18-02-2019...   \n",
       "4    data/A1/00391 Plant 0004 Plant 0004/18-02-2019...   \n",
       "..                                                 ...   \n",
       "989  data/B4/01019 Plant 0122 Plant 0122/18-02-2019...   \n",
       "990  data/B4/01020 Plant 0123 Plant 0123/18-02-2019...   \n",
       "991  data/B4/01021 Plant 0124 Plant 0124/18-02-2019...   \n",
       "992  data/B4/01022 Plant 0125 Plant 0125/18-02-2019...   \n",
       "993  data/B4/01023 Plant 0126 Plant 0126/18-02-2019...   \n",
       "\n",
       "                                         side_cam_path Rfid         Pos  \\\n",
       "0    data/A1/00387 Plant 0000 Plant 0000/18-02-2019...   A1  Plant 0000   \n",
       "1    data/A1/00388 Plant 0001 Plant 0001/18-02-2019...   A1  Plant 0001   \n",
       "2    data/A1/00389 Plant 0002 Plant 0002/18-02-2019...   A1  Plant 0002   \n",
       "3    data/A1/00390 Plant 0003 Plant 0003/18-02-2019...   A1  Plant 0003   \n",
       "4    data/A1/00391 Plant 0004 Plant 0004/18-02-2019...   A1  Plant 0004   \n",
       "..                                                 ...  ...         ...   \n",
       "989  data/B4/01019 Plant 0122 Plant 0122/18-02-2019...   B4  Plant 0122   \n",
       "990  data/B4/01020 Plant 0123 Plant 0123/18-02-2019...   B4  Plant 0123   \n",
       "991  data/B4/01021 Plant 0124 Plant 0124/18-02-2019...   B4  Plant 0124   \n",
       "992  data/B4/01022 Plant 0125 Plant 0125/18-02-2019...   B4  Plant 0125   \n",
       "993  data/B4/01023 Plant 0126 Plant 0126/18-02-2019...   B4  Plant 0126   \n",
       "\n",
       "     average_expert  Label  \n",
       "0              1.00      1  \n",
       "1              0.00      0  \n",
       "2              0.00      0  \n",
       "3              3.50      1  \n",
       "4              1.50      0  \n",
       "..              ...    ...  \n",
       "989            0.00      0  \n",
       "990            0.00      0  \n",
       "991            0.00      0  \n",
       "992            2.75      1  \n",
       "993            1.00      1  \n",
       "\n",
       "[994 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = normal\n",
    "# 1 = abnormal\n",
    "\n",
    "df[['Expert 1', 'Expert 2', 'Expert 3', 'Expert 4', 'average_expert']] = df[['Expert 1', 'Expert 2', 'Expert 3', 'Expert 4', 'average_expert']].replace({1: 0, 2: 0})\n",
    "df[['Expert 1', 'Expert 2', 'Expert 3', 'Expert 4', 'average_expert']] = df[['Expert 1', 'Expert 2', 'Expert 3', 'Expert 4', 'average_expert']].replace([3,4], 1)\n",
    "df['Label'] = df['Label'].round(0).astype(np.int64)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows the following structure:\n",
    "\n",
    "##### TensorFlow\n",
    "- Train Model 1: Color cam\n",
    "- Train Model 2: Side view cam\n",
    "- Predict both on test set \n",
    "- Weighted Voting\n",
    "- Majority Voting\n",
    "- Bayesian Consensus\n",
    "\n",
    "##### PyTorch\n",
    "- Train & Test Model 1: Color cam\n",
    "- Train & Test Model 2: Side view cam\n",
    "- Weighted Voting\n",
    "- Majority Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training: Once using TensorFlow (pre-trained model MobileNetV2) and once using PyTorch (own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow\n",
    "### CNN using transfer learning with MobileNetV2 as the base model\n",
    "The MobileNetV2 model is used as a feature extractor and then the extracted features are flattened and passed through a few dense layers with dropout before the final classification layer. The model is then trained on the input images using the ```ImageDataGenerator``` to generate batches of augmented images and passed through the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### COLOR CAM, MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 636 validated image filenames.\n",
      "Found 199 validated image filenames.\n",
      "Found 159 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set up a TensorFlow session to use the GPU if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator1 = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='color_cam_path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='raw')\n",
    "\n",
    "test_generator1 = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='color_cam_path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='raw')\n",
    "\n",
    "val_generator1 = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='color_cam_path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "80/80 [==============================] - 101s 1s/step - loss: 4.1949 - accuracy: 0.8066 - val_loss: 6.1235 - val_accuracy: 0.6792\n",
      "Epoch 2/4\n",
      "80/80 [==============================] - 93s 1s/step - loss: 1.2356 - accuracy: 0.8774 - val_loss: 0.5826 - val_accuracy: 0.8868\n",
      "Epoch 3/4\n",
      "80/80 [==============================] - 95s 1s/step - loss: 0.3746 - accuracy: 0.8931 - val_loss: 0.4522 - val_accuracy: 0.8679\n",
      "Epoch 4/4\n",
      "80/80 [==============================] - 97s 1s/step - loss: 0.2641 - accuracy: 0.9025 - val_loss: 0.3202 - val_accuracy: 0.8994\n",
      "Wall time: 6min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x265dd0237f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load the MobileNetV2 model\n",
    "mobilenet_model1 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# unfreeze the last few layers for fine-tuning\n",
    "for layer in mobilenet_model1.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# build the model\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    mobilenet_model1,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model1.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model1.fit(train_generator1, epochs=4, validation_data=val_generator1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Save model so it can be used later again without training again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "model1.save('model1_color_cam.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SIDE CAM, MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 636 validated image filenames.\n",
      "Found 199 validated image filenames.\n",
      "Found 159 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set up a TensorFlow session to use the GPU if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Define the data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator2 = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='side_cam_path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=10,\n",
    "    class_mode='raw')\n",
    "\n",
    "test_generator2 = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='side_cam_path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=10,\n",
    "    class_mode='raw')\n",
    "\n",
    "val_generator2 = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='color_cam_path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "64/64 [==============================] - 80s 1s/step - loss: 1.7277 - accuracy: 0.8758 - val_loss: 10.0173 - val_accuracy: 0.6792\n",
      "Epoch 2/4\n",
      "64/64 [==============================] - 64s 999ms/step - loss: 0.3175 - accuracy: 0.9167 - val_loss: 9.7951 - val_accuracy: 0.6792\n",
      "Epoch 3/4\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.3753 - accuracy: 0.9119 - val_loss: 7.8351 - val_accuracy: 0.6792\n",
      "Epoch 4/4\n",
      "64/64 [==============================] - 63s 978ms/step - loss: 0.1944 - accuracy: 0.9355 - val_loss: 13.9063 - val_accuracy: 0.6792\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266162c8b80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# load the MobileNetV2 model\n",
    "mobilenet_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# unfreeze the last few layers for fine-tuning\n",
    "for layer in mobilenet_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# build the model\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    mobilenet_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model2.fit(train_generator2, epochs=4, validation_data=val_generator2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Save model so it can be used later again without training again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "model2.save('model2_side_cam.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load already trained models and predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1 = load_model('model1_color_cam.h5')\n",
    "model2 = load_model('model2_side_cam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 482ms/step\n",
      "Prediction done, Model 1\n",
      "20/20 [==============================] - 9s 456ms/step\n",
      "Prediction done, Model 2\n",
      "25/25 [==============================] - 17s 669ms/step - loss: 0.2462 - accuracy: 0.9196\n",
      "Accuracy on test set for model number 1 :  0.9195979833602905\n",
      "20/20 [==============================] - 10s 471ms/step - loss: 0.6937 - accuracy: 0.9246\n",
      "Accuracy on test set for model number 2 :  0.9246231317520142\n",
      "Wall time: 49.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def predict(model, test_generator):\n",
    "    # predict the labels for test data\n",
    "    test_generator.reset()\n",
    "    pred = model.predict(test_generator)\n",
    "\n",
    "    # convert the predictions to binary labels\n",
    "    pred_labels = [1 if p >= 0.5 else 0 for p in pred]\n",
    "    \n",
    "    return pred_labels, pred\n",
    "\n",
    "def accuracy(model, test_generator, model_number):\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    print('Accuracy on test set for model number', model_number, ': ', accuracy)\n",
    "    \n",
    "    \n",
    "pred_labels1, pred1 = predict(model1, test_generator1)\n",
    "print('Prediction done, Model 1')\n",
    "pred_labels2, pred2 = predict(model2, test_generator2)\n",
    "print('Prediction done, Model 2')\n",
    "\n",
    "accuracy(model1, test_generator1, '1')\n",
    "accuracy(model2, test_generator2, '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6180904522613065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "weighted_pred = (0.4 * pred1) + (0.6 * pred2)\n",
    "threshold = 0.5\n",
    "binary_pred = (weighted_pred > threshold).astype(int)\n",
    "\n",
    "true_labels = test_generator1.labels\n",
    "accuracy = accuracy_score(true_labels, binary_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7236180904522613\n"
     ]
    }
   ],
   "source": [
    "# combine the predictions using majority voting\n",
    "combined_preds = np.round((preds1 + preds2) / 2)\n",
    "\n",
    "# convert to binary labels\n",
    "binary_preds = (combined_preds > 0.5).astype(int)\n",
    "\n",
    "# calculate accuracy'\n",
    "true_labels = test_generator1.labels\n",
    "accuracy = accuracy_score(true_labels, binary_preds)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7236180904522613"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# Compute the probability distributions for each model's predictions\n",
    "probs_model1 = softmax(preds1)\n",
    "probs_model2 = softmax(preds2)\n",
    "\n",
    "# Compute the product of the probabilities\n",
    "prod_probs = probs_model1 * probs_model2\n",
    "\n",
    "# Normalize the product of probabilities to obtain the consensus probabilities\n",
    "consensus_probs = prod_probs / np.sum(prod_probs, axis=1, keepdims=True)\n",
    "\n",
    "# Compute the final predictions using the consensus probabilities\n",
    "consensus_preds = np.argmax(consensus_probs, axis=1)\n",
    "\n",
    "# Compute the accuracy of the consensus predictions\n",
    "accuracy = accuracy_score(test_generator1.labels, consensus_preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Color cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define a transformation to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Split the dataframe into training and testing sets\n",
    "train_df = df.sample(frac=0.8, random_state=123)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# Define custom dataset classes to load the images and their labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['color_cam_path']\n",
    "        label = self.df.iloc[idx]['Label']\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create custom dataset objects for the training and testing sets\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, transform=transform)\n",
    "\n",
    "# Define data loaders for the training and testing sets\n",
    "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.605, Validation Loss: 0.624, Validation Accuracy: 63.82%\n",
      "Epoch: 2, Training Loss: 0.416, Validation Loss: 0.429, Validation Accuracy: 84.92%\n",
      "Epoch: 3, Training Loss: 0.237, Validation Loss: 0.327, Validation Accuracy: 91.46%\n",
      "Epoch: 4, Training Loss: 0.220, Validation Loss: 0.306, Validation Accuracy: 85.43%\n",
      "Epoch: 5, Training Loss: 0.154, Validation Loss: 0.404, Validation Accuracy: 88.94%\n",
      "Epoch: 6, Training Loss: 0.128, Validation Loss: 0.417, Validation Accuracy: 89.45%\n",
      "Epoch: 7, Training Loss: 0.107, Validation Loss: 0.366, Validation Accuracy: 88.94%\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 8, Training Loss: 0.068, Validation Loss: 0.337, Validation Accuracy: 89.95%\n",
      "Epoch: 9, Training Loss: 0.062, Validation Loss: 0.317, Validation Accuracy: 90.95%\n",
      "Test Accuracy: 90.95%\n",
      "Wall time: 19min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "for epoch in range(9):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate model on validation set\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print validation metrics\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print('Epoch: %d, Training Loss: %.3f, Validation Loss: %.3f, Validation Accuracy: %.2f%%' %\n",
    "          (epoch + 1, running_loss / len(trainloader), val_loss / len(testloader), val_accuracy))\n",
    "\n",
    "    # Adjust learning rate based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if val_loss < 10:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(net.state_dict(), 'model1_color_pytorch.pth')\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "# Load best model checkpoint and evaluate on test set\n",
    "net.load_state_dict(torch.load('model1_color_pytorch.pth'))\n",
    "net.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_correct / test_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>class_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.928098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_label  predicted_label  class_prob\n",
       "0             0                0    0.004411\n",
       "1             1                1    0.993673\n",
       "2             0                0    0.000332\n",
       "3             1                1    0.990157\n",
       "4             1                1    0.928098\n",
       "..          ...              ...         ...\n",
       "194           0                0    0.041295\n",
       "195           1                1    0.976391\n",
       "196           1                0    0.015404\n",
       "197           0                0    0.002822\n",
       "198           1                1    0.816817\n",
       "\n",
       "[199 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to predict label and class probability\n",
    "def predict(image):\n",
    "    with torch.no_grad():\n",
    "        output = net(image.unsqueeze(0))\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        label = torch.argmax(prob, dim=1).item()\n",
    "        prob = prob[0][1].item()\n",
    "    return label, prob\n",
    "\n",
    "# Iterate through test set and predict label and class probability for each image\n",
    "data = []\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        for i in range(len(inputs)):\n",
    "            true_label = labels[i].item()\n",
    "            predicted_label, class_prob = predict(inputs[i])\n",
    "            data.append({\n",
    "                'true_label': true_label,\n",
    "                'predicted_label': predicted_label,\n",
    "                'class_prob': class_prob\n",
    "            })\n",
    "\n",
    "# Convert list of dictionaries to dataframe\n",
    "results_df1 = pd.DataFrame(data)\n",
    "\n",
    "# Convert predicted label to binary value based on class probability\n",
    "results_df1['predicted_label'] = np.where(results_df1['class_prob'] > 0.5, 1, 0)\n",
    "results_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Side cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        if tensor.size(0) == 1:\n",
    "            # grayscale image\n",
    "            mean = torch.tensor(self.mean)[[0], [0], [0]]\n",
    "            std = torch.tensor(self.std)[[0], [0], [0]]\n",
    "        else:\n",
    "            # color image\n",
    "            mean = self.mean\n",
    "            std = self.std\n",
    "\n",
    "        return F.normalize(tensor, mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, Grayscale\n",
    "from PIL import Image\n",
    "\n",
    "# Define a transformation to apply to the images\n",
    "Normalize_transform = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3), # convert to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    Normalize_transform\n",
    "])\n",
    "# Split the dataframe into training and testing sets\n",
    "train_df = df.sample(frac=0.8, random_state=123)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['side_cam_path']\n",
    "        label = self.df.iloc[idx]['Label']\n",
    "        image = Image.open(img_path)\n",
    "        if image.mode != 'RGB':\n",
    "            # convert grayscale to RGB\n",
    "            image = Image.merge('RGB', [image]*3)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "# Create custom dataset objects for the training and testing sets\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, transform=transform)\n",
    "\n",
    "# Define data loaders for the training and testing sets\n",
    "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)  # adjust the input size of the first fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # adjust the view statement to match the output size of the second convolutional layer\n",
    "        x = x.view(-1, 16 * 53 * 53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = nn.Linear(10, 10) \n",
    "        self.fc5 = nn.Linear(10, 10) \n",
    "        self.fc6 = nn.Linear(10, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 53 * 53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.000, Validation Loss: 0.638, Validation Accuracy: 63.82%\n",
      "Epoch: 2, Training Loss: 0.000, Validation Loss: 0.621, Validation Accuracy: 67.34%\n",
      "Epoch: 3, Training Loss: 0.000, Validation Loss: 0.529, Validation Accuracy: 79.90%\n",
      "Epoch: 4, Training Loss: 0.000, Validation Loss: 0.636, Validation Accuracy: 78.89%\n",
      "Epoch: 5, Training Loss: 0.000, Validation Loss: 0.614, Validation Accuracy: 79.90%\n",
      "Epoch: 6, Training Loss: 0.000, Validation Loss: 0.641, Validation Accuracy: 82.41%\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 7, Training Loss: 0.000, Validation Loss: 0.660, Validation Accuracy: 80.40%\n",
      "Test Accuracy: 80.40%\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "for epoch in range(7):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Reset running_loss to 0 at the end of each epoch\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Evaluate model on validation set\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print validation metrics\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print('Epoch: %d, Training Loss: %.3f, Validation Loss: %.3f, Validation Accuracy: %.2f%%' %\n",
    "          (epoch + 1, running_loss / len(trainloader), val_loss / len(testloader), val_accuracy))\n",
    "\n",
    "    # Adjust learning rate based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if val_loss < 10:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(net.state_dict(), 'model2_side_pytorch.pth')\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "# Load best model checkpoint and evaluate on test set\n",
    "net.load_state_dict(torch.load('model2_side_pytorch.pth'))\n",
    "net.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_correct / test_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Class Probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     True Label  Predicted Label  Class Probabilities\n",
       "0             0                0             0.002672\n",
       "1             1                1             0.960924\n",
       "2             0                0             0.008700\n",
       "3             1                1             0.961159\n",
       "4             1                0             0.024407\n",
       "..          ...              ...                  ...\n",
       "194           0                0             0.004608\n",
       "195           1                1             0.931021\n",
       "196           1                0             0.022019\n",
       "197           0                0             0.295605\n",
       "198           1                0             0.016001\n",
       "\n",
       "[199 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to hold the results\n",
    "results = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# Turn off gradient calculations to save memory and computation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "\n",
    "        # Get the predicted class labels and class probabilities\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        # Convert PyTorch tensors to numpy arrays\n",
    "        true_labels = labels.numpy()\n",
    "        predicted_labels = predicted.numpy()\n",
    "        class_probs = probs.numpy()[:, 1]  # Only include probabilities for class 1\n",
    "\n",
    "        # Append the results to the list\n",
    "        for i in range(len(true_labels)):\n",
    "            results.append([true_labels[i], predicted_labels[i], class_probs[i]])\n",
    "\n",
    "# Convert the list of results to a pandas DataFrame\n",
    "results_df2 = pd.DataFrame(results, columns=['True Label', 'Predicted Label', 'Class Probabilities'])\n",
    "results_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_probs_model1_color</th>\n",
       "      <th>pred_model1_color</th>\n",
       "      <th>class_probs_model2_side</th>\n",
       "      <th>pred_model2_side</th>\n",
       "      <th>true_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993673</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990157</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.928098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.041295</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.976391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.015404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.002822</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.816817</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_probs_model1_color  pred_model1_color  class_probs_model2_side  \\\n",
       "0                    0.004411                  0                 0.002672   \n",
       "1                    0.993673                  1                 0.960924   \n",
       "2                    0.000332                  0                 0.008700   \n",
       "3                    0.990157                  1                 0.961159   \n",
       "4                    0.928098                  1                 0.024407   \n",
       "..                        ...                ...                      ...   \n",
       "194                  0.041295                  0                 0.004608   \n",
       "195                  0.976391                  1                 0.931021   \n",
       "196                  0.015404                  0                 0.022019   \n",
       "197                  0.002822                  0                 0.295605   \n",
       "198                  0.816817                  1                 0.016001   \n",
       "\n",
       "     pred_model2_side  true_labels  \n",
       "0                   0            0  \n",
       "1                   1            1  \n",
       "2                   0            0  \n",
       "3                   1            1  \n",
       "4                   0            1  \n",
       "..                ...          ...  \n",
       "194                 0            0  \n",
       "195                 1            1  \n",
       "196                 0            1  \n",
       "197                 0            0  \n",
       "198                 0            1  \n",
       "\n",
       "[199 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "merged_df['class_probs_model1_color'] = results_df1['class_prob']\n",
    "merged_df['pred_model1_color'] = results_df1['predicted_label']\n",
    "merged_df['class_probs_model2_side'] = results_df2['Class Probabilities']\n",
    "merged_df['pred_model2_side'] = results_df2['Predicted Label']\n",
    "merged_df['true_labels'] = results_df1['true_label']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8241206030150754"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model1_color = merged_df['pred_model1_color'].tolist()\n",
    "pred_model2_side = merged_df['pred_model2_side'].tolist()\n",
    "\n",
    "pred_majority = [np.argmax(np.bincount([pred_model1_color[i], pred_model2_side[i]])) for i in range(len(pred_model1_color))]\n",
    "\n",
    "merged_df['pred_majority'] = pred_majority\n",
    "acc = accuracy_score(merged_df['true_labels'], merged_df['pred_majority'])\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045226130653267"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_vote(row):\n",
    "    # higher weight for the model with higher accuracy\n",
    "    w1 = 0.9\n",
    "    w2 = 0.1\n",
    "\n",
    "    vote = w1 * row['class_probs_model1_color'] + w2 * row['class_probs_model2_side']\n",
    "\n",
    "    return round(vote, 3)\n",
    "\n",
    "merged_df['weighted_vote'] = merged_df.apply(weighted_vote, axis=1)\n",
    "merged_df['weighted_vote_binary'] = merged_df['weighted_vote'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "acc = accuracy_score(merged_df['true_labels'], merged_df['weighted_vote_binary'])\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
